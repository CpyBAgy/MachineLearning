{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Лабораторная 5 – 10 баллов (дедлайн 25.04.2025)\n",
    "## Вариант 1 (простой) – 5 баллов\n",
    "- С помощью библиотеки Optuna настройте гиперпараметры сверточной нейронной сети (например, число слоев, размер фильтра и тд, оптимизатор — не гиперпараметр).\n",
    "- Гиперпараметры определите сами.\n",
    "- Гиперпараметров должно быть не менее 5.\n",
    "- Обучение проводить на датасете CIFAR-10.\n"
   ],
   "id": "307611d6d2328c42"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Шаг №0 - Импорт библиотек",
   "id": "14b68f88c79ca485"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import optuna\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ],
   "id": "5f73925488bdd5c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Шаг №1 - Проверка доступности GPU и настройка",
   "id": "24b0bc07f9ffa94b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    print(f\"Найдено {len(physical_devices)} GPU:\")\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "        print(f\" - {device.name} с динамическим выделением памяти\")\n",
    "else:\n",
    "    print(\"GPU не найдена, используется CPU\")"
   ],
   "id": "3338b3f7c45d43e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Шаг №2 - Загрузка и предобработка данных",
   "id": "2266f1dd5d078575"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    x_train = x_train.astype('float32') / 255.0\n",
    "    x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "    y_train = to_categorical(y_train, 10)\n",
    "    y_test = to_categorical(y_test, 10)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ],
   "id": "48a7705ce9c40ce5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Шаг №3 - Построение модели с гиперпараметрами\n",
    "## Гиперпараметры:\n",
    "- Количество сверточных блоков (от 2 до 4)\n",
    "- Начальное количество фильтров (от 32 до 96)\n",
    "- Размер ядра свертки (от 3 до 5)\n",
    "- Скорость обучения (от 1e-4 до 1e-2)\n",
    "- Коэффициент отсева (Dropout) (от 0.2 до 0.5)\n",
    "- Использовать ли BatchNormalization\n",
    "- Количество нейронов в полносвязном слое (от 128 до 512)\n",
    "- Размер батча (от 32 до 128)"
   ],
   "id": "9a0433d4a2cb76ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_model(trial):\n",
    "    n_conv_blocks = trial.suggest_int('n_conv_blocks', 2, 4)\n",
    "\n",
    "    initial_filters = trial.suggest_int('initial_filters', 32, 96, step=16)\n",
    "\n",
    "    kernel_size = trial.suggest_int('kernel_size', 3, 5, step=2)\n",
    "\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5, step=0.1)\n",
    "\n",
    "    use_batch_norm = trial.suggest_categorical('use_batch_norm', [True, False])\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    for i in range(n_conv_blocks):\n",
    "        if i == 0:\n",
    "            model.add(Conv2D(initial_filters * (2 ** i), kernel_size=kernel_size, padding='same',\n",
    "                             activation='relu', input_shape=(32, 32, 3)))\n",
    "        else:\n",
    "            model.add(Conv2D(initial_filters * (2 ** i), kernel_size=kernel_size, padding='same',\n",
    "                             activation='relu'))\n",
    "\n",
    "        if use_batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Conv2D(initial_filters * (2 ** i), kernel_size=kernel_size, padding='same',\n",
    "                         activation='relu'))\n",
    "\n",
    "        if use_batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    dense_units = trial.suggest_int('dense_units', 128, 512, step=64)\n",
    "\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ],
   "id": "b246f37bdd15282b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Шаг №4 - Определение функции для обучения и оценки модели",
   "id": "31ce436a9034e538"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    x_train, y_train, x_test, y_test = load_data()\n",
    "\n",
    "    model = create_model(trial)\n",
    "\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_split=0.1,  # 10% данных для валидации\n",
    "        epochs=30,  # Максимальное количество эпох\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    _, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "    return accuracy"
   ],
   "id": "8901fee99b77e875",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Шаг №5 - Запуск",
   "id": "b257834bbe789a97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    print(\"Начинаем оптимизацию гиперпараметров с Optuna...\")\n",
    "\n",
    "    # Создаем исследование Optuna с хранилищем SQLite для параллельного запуска\n",
    "    study = optuna.create_study(\n",
    "        direction='maximize',\n",
    "        study_name='cnn_cifar10_optimization',\n",
    "        storage='sqlite:///optuna_study.db',\n",
    "        load_if_exists=True\n",
    "    )\n",
    "\n",
    "    study.optimize(objective, n_trials=20, n_jobs=5)\n",
    "\n",
    "    print(\"Лучшие гиперпараметры:\")\n",
    "    for key, value in study.best_params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "    print(f\"Лучшая достигнутая точность: {study.best_value:.4f}\")\n",
    "\n",
    "    try:\n",
    "        fig = optuna.visualization.plot_param_importances(study)\n",
    "        fig.show()\n",
    "\n",
    "        fig = optuna.visualization.plot_optimization_history(study)\n",
    "        fig.show()\n",
    "\n",
    "        fig = optuna.visualization.plot_contour(study, params=['learning_rate', 'dropout_rate'])\n",
    "        fig.show()\n",
    "    except:\n",
    "        print(\"Не удалось создать визуализацию. Возможно, нужно установить plotly.\")\n",
    "\n",
    "    print(\"Обучаем лучшую модель...\")\n",
    "    x_train, y_train, _, _ = load_data()\n",
    "    best_model = create_model(optuna.trial.FixedTrial(study.best_params))\n",
    "    best_model.fit(x_train, y_train, epochs=30, batch_size=study.best_params['batch_size'])\n",
    "\n",
    "    best_model.save('best_cnn_cifar10_model.h5')\n",
    "    print(\"Лучшая модель сохранена как 'best_cnn_cifar10_model.h5'\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "66545595d632ac29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Выводы:\n",
    "## Описание эксперимента\n",
    "Для проведения эксперимента использовалась библиотека Optuna, которая позволяет автоматизировать процесс подбора гиперпараметров модели. Всего было проведено 30 испытаний с различными комбинациями гиперпараметров.\n",
    "##Оптимизируемые гиперпараметры:\n",
    "\n",
    "- Количество сверточных блоков (n_conv_blocks): от 1 до 3\n",
    "- Начальное количество фильтров (initial_filters): от 32 до 64\n",
    "- Размер ядра свертки (kernel_size): от 3 до 5\n",
    "- Коэффициент отсева, Dropout (dropout_rate): от 0.2 до 0.5\n",
    "- Использование пакетной нормализации (use_batch_norm): True/False\n",
    "- Количество нейронов в полносвязном слое (dense_units): от 128 до 512\n",
    "- Скорость обучения (learning_rate): от 1e-4 до 1e-2\n",
    "- Размер батча (batch_size): 64, 128 или 256\n",
    "\n",
    "## Результаты\n",
    "```\n",
    "Оптимизация завершена!\n",
    "Общее время выполнения: 88.78 минут\n",
    "\n",
    "Лучшие гиперпараметры:\n",
    "  n_conv_blocks: 3\n",
    "  initial_filters: 64\n",
    "  kernel_size: 3\n",
    "  dropout_rate: 0.4\n",
    "  use_batch_norm: True\n",
    "  dense_units: 384\n",
    "  learning_rate: 0.00037519342722137103\n",
    "  batch_size: 64\n",
    "\n",
    "Лучшая достигнутая точность: 0.8497\n",
    "\n",
    "Обучаем лучшую модель на полном наборе данных...\n",
    "...\n",
    "Epoch 25/25\n",
    "704/704 [==============================] - 10s 15ms/step - loss: 0.2205 - accuracy: 0.9235 - val_loss: 0.4853 - val_accuracy: 0.8620\n",
    "\n",
    "Лучшая модель сохранена в 'prev/best_cnn_cifar10_model.h5'\n",
    "\n",
    "Важность параметров:\n",
    "  learning_rate: 0.7477\n",
    "  n_conv_blocks: 0.1149\n",
    "  batch_size: 0.0491\n",
    "  dense_units: 0.0291\n",
    "  use_batch_norm: 0.0281\n",
    "  initial_filters: 0.0161\n",
    "  dropout_rate: 0.0125\n",
    "  kernel_size: 0.0024\n",
    "\n",
    "График важности параметров сохранен в 'importance.png'\n",
    "```\n",
    "\n",
    "## График важности параметров\n",
    "![Важность_гиперпараметров](importance.jpg)\n",
    "## Выводы\n",
    "1. Наиболее критическим гиперпараметром для данной задачи является скорость обучения (learning rate), что согласуется с общепринятыми представлениями в глубоком обучении.\n",
    "2. Глубокая архитектура с тремя сверточными блоками превзошла более мелкие модели, что указывает на необходимость достаточной сложности модели для эффективного извлечения признаков из изображений CIFAR-10.\n",
    "3. Применение техник регуляризации, таких как Dropout и BatchNormalization, значительно улучшило производительность модели.\n",
    "4. Оптимальный баланс между размером модели и ее производительностью был достигнут при использовании архитектуры средней сложности."
   ],
   "id": "30bf7effc37e3859"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d6ea7c6f840b8e4d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
