import os
import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf
import torch
import warnings
import platform
from datetime import datetime
from IPython.display import Audio, display, HTML

warnings.filterwarnings("ignore")

device = "cpu"
if torch.cuda.is_available():
    device = "cuda"
    print(f"üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ–º GPU: {torch.cuda.get_device_name(0)}")
elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
    device = "mps"
    print(f"üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ–º Apple Silicon GPU (MPS)")
else:
    print(f"‚ö†Ô∏è GPU –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU")

torch.set_num_threads(4)

RESULTS_DIR = "generated_music"
PLOTS_DIR = os.path.join(RESULTS_DIR, "plots")
os.makedirs(RESULTS_DIR, exist_ok=True)
os.makedirs(PLOTS_DIR, exist_ok=True)

print(f"üñ•Ô∏è  –°–∏—Å—Ç–µ–º–∞: {platform.system()} {platform.version()}")
print(f"üêç Python: {platform.python_version()}")
print(f"üî• PyTorch: {torch.__version__}")

def save_audio(audio_data, filename, model_name, prompt, sample_rate=32000):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞—É–¥–∏–æ, –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –ø–ª–µ–µ—Ä"""
    if isinstance(audio_data, torch.Tensor):
        audio_data = audio_data.detach().cpu().numpy()

    if len(audio_data.shape) > 1 and audio_data.shape[0] <= 2:
        audio_data = audio_data.T

    if audio_data.max() > 1.0 or audio_data.min() < -1.0:
        audio_data = np.clip(audio_data, -1.0, 1.0)

    sf.write(filename, audio_data, sample_rate)
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filename}")

    display(Audio(audio_data, rate=sample_rate))

    try:
        import librosa
        import librosa.display

        plt.figure(figsize=(12, 6))

        plt.suptitle(f"–ú–æ–¥–µ–ª—å: {model_name}", fontsize=16, y=0.99)
        plt.title(f"–ü—Ä–æ–º–ø—Ç: '{prompt}'", fontsize=10)

        D = librosa.amplitude_to_db(np.abs(librosa.stft(audio_data)), ref=np.max)
        librosa.display.specshow(D, y_axis='log', x_axis='time', sr=sample_rate)
        plt.colorbar(format='%+2.0f dB')

        plot_filename = os.path.join(PLOTS_DIR, os.path.basename(filename).replace('.wav', '.png'))
        plt.tight_layout()
        plt.savefig(plot_filename)
        plt.close()
    except ImportError:
        print("‚ö†Ô∏è librosa –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã")

    return True

model_results = {}

# ===================== –§–£–ù–ö–¶–ò–ò –ì–ï–ù–ï–†–ê–¶–ò–ò –ú–£–ó–´–ö–ò =====================

def generate_with_musicgen(prompt="pop music with catchy chorus and electronic beats", duration=8):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º—É–∑—ã–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—è Meta's MusicGen Small –º–æ–¥–µ–ª—å"""
    model_name = "MusicGen Small"
    print(f"\nüéµ --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é {model_name} ---")

    try:
        from audiocraft.models import MusicGen

        print("‚öôÔ∏è –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å...")
        model = MusicGen.get_pretrained("facebook/musicgen-small")
        model.set_generation_params(duration=duration)

        descriptions = [prompt]

        print(f"üéº –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º—É–∑—ã–∫—É –ø–æ –ø—Ä–æ–º–ø—Ç—É: '{prompt}'...")
        wav = model.generate(descriptions, progress=True)

        for idx, (audio, desc) in enumerate(zip(wav, descriptions)):
            filename = f"{RESULTS_DIR}/musicgen_small_{idx+1}.wav"
            save_audio(audio[0], filename, model_name, desc, sample_rate=32000)

        return True
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å {model_name}: {e}")
        return False

def generate_with_audioldm(prompt="pop music with catchy chorus and electronic beats", duration=10):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º—É–∑—ã–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—è AudioLDM –º–æ–¥–µ–ª—å"""
    model_name = "AudioLDM"
    print(f"\nüéµ --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é {model_name} ---")

    try:
        from diffusers import AudioLDMPipeline

        print("‚öôÔ∏è –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å...")
        pipe = AudioLDMPipeline.from_pretrained(
            "cvssp/audioldm-s-full-v2",
            torch_dtype=torch.float32 if device == "mps" else torch.float16
        )
        pipe = pipe.to(device)

        num_inference_steps = 10 if device == "cpu" else 50

        print(f"üéº –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º—É–∑—ã–∫—É –ø–æ –ø—Ä–æ–º–ø—Ç—É: '{prompt}'...")
        audio = pipe(
            prompt,
            num_inference_steps=num_inference_steps,
            audio_length_in_s=duration
        ).audios[0]

        filename = f"{RESULTS_DIR}/audioldm_{datetime.now().strftime('%Y%m%d_%H%M%S')}.wav"
        save_audio(audio, filename, model_name, prompt, sample_rate=16000)

        return True
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å {model_name}: {e}")
        return False

def generate_with_musicldm(prompt="pop music with catchy melody and modern production", duration=5):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º—É–∑—ã–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—è MusicLDM –º–æ–¥–µ–ª—å"""
    model_name = "MusicLDM"
    print(f"\nüéµ --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é {model_name} ---")

    try:
        from diffusers import DiffusionPipeline

        print("‚öôÔ∏è –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å...")
        pipe = DiffusionPipeline.from_pretrained(
            "ucsd-reach/musicldm",
            torch_dtype=torch.float32
        )
        pipe = pipe.to(device)

        num_inference_steps = 10 if device == "cpu" else 50

        print(f"üéº –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º—É–∑—ã–∫—É –ø–æ –ø—Ä–æ–º–ø—Ç—É: '{prompt}'...")
        audio = pipe(
            prompt,
            num_inference_steps=num_inference_steps,
            audio_length_in_s=duration
        ).audios[0]

        filename = f"{RESULTS_DIR}/musicldm_{datetime.now().strftime('%Y%m%d_%H%M%S')}.wav"
        save_audio(audio, filename, model_name, prompt, sample_rate=16000)

        return True
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å {model_name}: {e}")
        return False

def generate_with_audiogen(prompt="pop music with catchy chorus and electronic beats", duration=5):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º—É–∑—ã–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—è AudioGen –º–æ–¥–µ–ª—å"""
    model_name = "AudioGen"
    print(f"\nüéµ --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é {model_name} ---")

    try:
        from audiocraft.models import AudioGen

        print("‚öôÔ∏è –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å...")
        model = AudioGen.get_pretrained("facebook/audiogen-medium")
        model.set_generation_params(duration=duration)

        descriptions = [prompt]

        print(f"üéº –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º—É–∑—ã–∫—É –ø–æ –ø—Ä–æ–º–ø—Ç—É: '{prompt}'...")
        wav = model.generate(descriptions, progress=True)

        for idx, (audio, desc) in enumerate(zip(wav, descriptions)):
            filename = f"{RESULTS_DIR}/audiogen_{datetime.now().strftime('%Y%m%d_%H%M%S')}.wav"
            save_audio(audio[0], filename, model_name, desc, sample_rate=16000)

        return True
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å {model_name}: {e}")
        return False

def generate_with_musicgen_melody(prompt="pop music with catchy chorus and electronic beats", duration=8):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º—É–∑—ã–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—è MusicGen Melody –º–æ–¥–µ–ª—å"""
    model_name = "MusicGen Melody"
    print(f"\nüéµ --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é {model_name} ---")

    try:
        from audiocraft.models import MusicGen

        print("‚öôÔ∏è –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å...")
        model = MusicGen.get_pretrained("facebook/musicgen-melody")
        model.set_generation_params(duration=duration)

        descriptions = [prompt]

        print(f"üéº –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º—É–∑—ã–∫—É –ø–æ –ø—Ä–æ–º–ø—Ç—É: '{prompt}'...")
        wav = model.generate(descriptions, progress=True)

        for idx, (audio, desc) in enumerate(zip(wav, descriptions)):
            filename = f"{RESULTS_DIR}/musicgen_melody_{datetime.now().strftime('%Y%m%d_%H%M%S')}.wav"
            save_audio(audio[0], filename, model_name, desc, sample_rate=32000)

        return True
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å {model_name}: {e}")
        return False

def generate_with_audioldm2(prompt="pop music with catchy chorus and electronic beats", duration=5):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º—É–∑—ã–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—è AudioLDM2 –º–æ–¥–µ–ª—å"""
    model_name = "AudioLDM2"
    print(f"\nüéµ --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é {model_name} ---")

    try:
        from diffusers import AudioLDM2Pipeline

        print("‚öôÔ∏è –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å...")
        pipe = AudioLDM2Pipeline.from_pretrained(
            "cvssp/audioldm2",
            torch_dtype=torch.float32
        )
        pipe = pipe.to(device)

        num_inference_steps = 10 if device == "cpu" else 50

        print(f"üéº –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º—É–∑—ã–∫—É –ø–æ –ø—Ä–æ–º–ø—Ç—É: '{prompt}'...")
        audio = pipe(
            prompt,
            num_inference_steps=num_inference_steps,
            audio_length_in_s=duration
        ).audios[0]

        filename = f"{RESULTS_DIR}/audioldm2_{datetime.now().strftime('%Y%m%d_%H%M%S')}.wav"
        save_audio(audio, filename, model_name, prompt, sample_rate=16000)

        return True
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å {model_name}: {e}")
        return False



pop_prompt = "pop music with catchy chorus, electronic beats and uplifting melody"

print("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º—É–∑—ã–∫–∏...\n")

duration = 5 if device == "cpu" else 8

model_results["MusicGen Small"] = generate_with_musicgen(pop_prompt, duration=duration)

model_results["AudioLDM"] = generate_with_audioldm(pop_prompt, duration=duration)

model_results["MusicLDM"] = generate_with_musicldm(pop_prompt, duration=duration)

model_results["AudioGen"] = generate_with_audiogen(pop_prompt, duration=duration)

model_results["MusicGen Melody"] = generate_with_musicgen_melody(pop_prompt, duration=duration)

model_results["AudioLDM2"] = generate_with_audioldm2(pop_prompt, duration=duration)


print("\n\nüìä --- –ò—Ç–æ–≥–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ ---")
successful_models = 0
results_table = "<table style='width:100%; border-collapse:collapse; margin:20px 0;'>"
results_table += "<tr style='background:#f2f2f2;'><th style='padding:10px; border:1px solid #ddd;'>–ú–æ–¥–µ–ª—å</th><th style='padding:10px; border:1px solid #ddd;'>–°—Ç–∞—Ç—É—Å</th></tr>"

for model_name, success in model_results.items():
    status = "‚úÖ –£–°–ü–ï–®–ù–û" if success else "‚ùå –û–®–ò–ë–ö–ê"
    status_color = "green" if success else "red"
    results_table += f"<tr><td style='padding:10px; border:1px solid #ddd;'>{model_name}</td>"
    results_table += f"<td style='padding:10px; border:1px solid #ddd; color:{status_color};'>{status}</td></tr>"

    if success:
        successful_models += 1

results_table += "</table>"

print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {successful_models}/{len(model_results)}")
display(HTML(results_table))

if successful_models < 3:
    print("\n‚ö†Ô∏è –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –º–µ–Ω–µ–µ 3 –º–æ–¥–µ–ª–µ–π. –í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:")
    print("  1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π")
    print("  2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é (librosa, audiocraft, diffusers)")
    print("  3. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å –Ω–∞ GPU, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ")
    print("  4. –£–º–µ–Ω—å—à–∏—Ç–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (parameter duration)")
elif successful_models < len(model_results):
    print("\n‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª–∏ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ:")
    print("  1. –ó–∞–ø—É—Å—Ç–∏—Ç—å –∏—Ö –æ—Ç–¥–µ–ª—å–Ω–æ")
    print("  2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–π –ø–∞–º—è—Ç–∏")
    print("  3. –£–º–µ–Ω—å—à–∏—Ç—å –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –º–æ–¥–µ–ª–µ–π —Å –æ—à–∏–±–∫–∞–º–∏")
else:
    print("\nüéâ –í—Å–µ –º–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∏ –º—É–∑—ã–∫—É!")